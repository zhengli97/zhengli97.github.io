<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Zheng Li (李政) | Home</title>
  <meta name="description" content="Zheng Li">
  <meta name="author" content="Zheng Li">
  <meta property="og:title" content="Zheng Li" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://zhengli97.github.io" />
  <meta property="og:site_name" content="Zheng Li" />
  <link rel="canonical" href="https://zhengli97.github.io" />

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,600' rel='stylesheet' type='text/css'>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton/normalize.css>
  <link rel="stylesheet" href=/libs/external/skeleton/skeleton.css>
  <link rel="stylesheet" href=/libs/custom/my_css.css>

  <!-- JQuery
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script src=/libs/external/jquery-3.1.1.min.js></script>

  <!-- Font-Awesome
  –––––––––––––––––––––––––––––––––––––––––––––––––– 
  <link rel="stylesheet" href=/libs/external/font-awesome-4.7.0/css/font-awesome.min.css> -->
  <link rel="stylesheet" href=/libs/external/fontawesome-free-6.6.0-web/css/all.min.css>

  <!-- Academicons
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/academicons-1.8.6/css/academicons.min.css>

  <!-- Skeleton tabs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/skeleton_tabs/skeleton-tabs.css>
  <script src=/libs/external/skeleton_tabs/skeleton-tabs.js></script>

  <!-- Timeline
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href=/libs/external/timeline.css>

  <!-- Scripts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link rel="stylesheet" href=/libs/external/github-prettify-theme.css>-->
  <script src=/libs/custom/my_js.js></script>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href=/libs/icon.png>
  <link rel="shortcut icon" type="image/png" href=/libs/icon.png>

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">

    <section class="header">
      <div class="row">
        <div class="three columns">
          <a href="/"><img class="u-max-full-width" src='/assets/pics/touxiang.png'></a>
        </div>
        <div class="nine columns main-description">
            <h1>Zheng Li (李政)</h1>
            <p>PhD Student, Nankai University</p>
            <p>zhengli97 [AT] mail.nankai.edu.cn</p>
            <p>Hangzhou, Zhejiang, China</p>
            <p>
              <!-- <span onclick="window.open('')" style="cursor: pointer">
                <i class="fa-brands fa-bluesky" style="padding-top: 10px"></i>
              </span>

              <span onclick="window.open('')" style="cursor: pointer">
                <i class="fa-brands fa-twitter fa-lg"></i>
              </span>

              <span onclick="window.open('')" style="cursor: pointer">
                <i class="fa-brands fa-linkedin fa-lg"></i>
              </span> -->

              <span onclick="window.open('https://www.researchgate.net/profile/Zheng-Li-132')" style="cursor: pointer">
                <i class="fa-brands fa-researchgate"></i> ResearchGate 
              </span>

              <span onclick="window.open('https://github.com/zhengli97')" style="cursor: pointer">
                <i class="fa-brands fa-github fa-lg"></i> Github 
              </span>

              <span onclick="window.open('https://scholar.google.com/citations?user=qhKtNSIAAAAJ&hl=en')" style="cursor: pointer">
                <i class="ai ai-google-scholar ai-lg" aria-hidden="true"></i> Google Scholar 
              </span>
            </p>
        </div>
      </div>
    </section>

    <div class="navbar-spacer"></div>
    <nav class="navbar">
      <div class="container">
        <ul class="navbar-list">
          <li class="navbar-item"><a class="navbar-link" href=/index.html#bio>Bio</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#news>News</a></li>
          <!-- <li class="navbar-item"><a class="navbar-link" href=/index.html#prospective-students>Prospective Students</a></li> -->
          <li class="navbar-item"><a class="navbar-link" href=/index.html#publications>Publications</a></li>
          <!--<li class="navbar-item"><a class="navbar-link" href=/index.html#projects>Projects</a></li>-->
          <li class="navbar-item"><a class="navbar-link" href=/index.html#experience>Experiences</a></li>
          <li class="navbar-item"><a class="navbar-link" href=/index.html#misc>Misc</a></li>
        </ul>
      </div>
    </nav>

    <!-- ========== BIO ========== -->
<div class="docs-section" id="bio">
  <h4>Bio</h4>
  <p>
    I am currently a third-year Ph.D. student at Tianjin Key Laboratory of Visual Computing and Intelligent Perception (VCIP), 
    Nankai University, advised by <a href="https://scholar.google.com/citations?user=oamjJdYAAAAJ" target="_blank">Prof. Xiang Li</a> 
    and <a href="https://scholar.google.com/citations?user=6CIDtZQAAAAJ" target="_blank">Prof. Jian Yang</a>. 
    <!-- I am also a research intern at Alibaba DAMO Academy, mentored by <a href="https://scholar.google.com/citations?user=oRhJHmIAAAAJ" target="_blank">Dr. Yibing Song</a>. -->
    My research mainly focuses on vision-language models, multi-modal learning and efficient model computing.
  </p>

  <!-- <p>
    I am also maintaining a curated list <a href="https://github.com/zhengli97/Awesome-Prompt-Learning-for-Vision-Language-Models" target="_blank">[Links]</a>
    <img src="https://img.shields.io/github/stars/zhengli97/Awesome-Prompt-Learning-for-Vision-Language-Models?style=social"/> 
    of prompt learning methods for vision-language models. Feel free to check it out~
  </p> -->
  <p>
    The code of my research work will be open-source, and I will also attach a detailed Chinese interpretation of the paper. 
    Although the interpretation may be somewhat fragmented, I will do my best to present the insights and ideas behind the paper.
  </p><p>
    The journey of scientific research is challenging, but I'm passionate about my work. 
    If you're interested in my research or encounter any problems, feel free to contact me via email (zhengli97 [at] qq.com).
  </p>
</div>


<div class="docs-section" id="news">
  <h4>News</h4>
  <ul>
    <li>Dec.2024. Our new work ATPrompt is now avavilable on arXiv. <a href="https://arxiv.org/abs/2412.09442">[Link]</a> <a href="https://github.com/zhengli97/ATPrompt">[Code]</a> <a href="https://zhengli97.github.io/ATPrompt/">[Project Page]</a>.</li>
    <li>Oct.2024. I was invited to gave a talk on Jiangmen(将门) about prompt learning methods. <a href="https://www.techbeat.net/talk-info?id=915">[Link]</a></li>
    <li>Mar.2024. We released a curated <a href="https://github.com/zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs">list</a> of prompt/adapter learning methods for VLMs. Feel free to check it out~</li>
    <li>Feb.2024. <a href="https://arxiv.org/abs/2403.02781">PromptKD</a>  was accepted by CVPR 2024. Code is public avavilable at <a href="https://github.com/zhengli97/PromptKD">GitHub</a>.</li>
    <details>
      <summary><li>&ensp;Before 2024: </li></Summary>
      <li>May.2023. <a href="https://arxiv.org/abs/2305.12954">DM-KD</a> is now avavilable on arxiv. Code is public avavilable at <a href="https://github.com/zhengli97/DM-KD">Github</a>.</li>
      <li>Jan.2023. <a href="https://arxiv.org/abs/2211.16231">CTKD</a> was accepted by AAAI 2023. Code is public avavilable at <a href="https://github.com/zhengli97/CTKD">Github</a>.</li>
     </details>
  </ul>
</div>


<!-- <div class="docs-section" id="prospective-students">  
  <h4>Prospective Students</h4>
  <p>
  <span style="display: inline-block; margin-bottom: 5px">
    <b>I'm recruiting PhD students to start Fall 2025 at the University of Washington!</b> 
  </span>
  <br/> 
  <span style="display: inline-block; margin-bottom: 5px">
    I'm looking for students passionate about developing new <u>social media algorithms</u>, both broadly and within the scope of this <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2403434" target="_blank">NSF grant</a> (collaboration with Stanford and Northwestern). For other examples, please see my recent publications. <br/>
  </span>
  <span style="display: inline-block; margin-bottom: 5px">
    Students with strong technical skills and background or interest in social network analysis, machine learning, causal inference, or natural language processing would be a great fit.
  </span>
  <br/>
  <span style="display: inline-block; margin-bottom: 5px">
    If you are interested, please apply to the UW iSchool <a href="https://ischool.uw.edu/programs/phd/admissions" target="_blank">PhD program</a> and mention me in your application.
  </span>
  <br/>
  <span>
    If you have any questions, feel free to reach out.
  </span>
  </p> 
</div> -->

<!-- ========== PUBLICATIONS ========== -->
<div class="docs-section" id="publications">
  <h4>Publications</h4>

  <p>Most recent publications are on <a href="https://scholar.google.com/citations?user=qhKtNSIAAAAJ&hl=en" target="_blank">Google Scholar</a>.<br/>
  <sup>#</sup> indicates corresponding author.
  </p>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#papers-selected">Selected</div></li>
    <li><div class="button" data-ref="#papers-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="papers-selected">
      
      
        <div class="paper">
          <p class="title"><b>Advancing Textual Prompt Learning with Anchored Attributes.</b></p>
          <p><b>Zheng Li</b>, Yibing Song, Ming-Ming Cheng, Xiang Li<sup>#</sup>, Jian Yang<sup>#</sup>.</p>
          <p><b>arxiv 2024</b></p>
          <p></p>
          <div class="paper-buttons">
            
              <!-- <a class="button" href="" target="_blank">Paper</a> -->
              <a class="button" href="https://arxiv.org/abs/2412.09442" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/ATPrompt" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://zhengli97.github.io/ATPrompt/" target="_blank">Project Page</a>
            

            
              <a class="button" href="https://zhuanlan.zhihu.com/p/11787739769" target="_blank">中文解读</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>PromptKD: Unsupervised Prompt Distillation for Vision-Language Models.</b></p>
          <p><b>Zheng Li</b>, Xiang Li<sup>#</sup>, Xinyi Fu, Xin Zhang, Weiqiang Wang, Shuo Chen, Jian Yang<sup>#</sup></p>
          <p><b>CVPR 2024</b></p>
          <p>PromptKD is a simple and effective <i>prompt-driven unsupervised distillation framework</i> for VLMs (e.g., CLIP), with state-of-the-art performance.</p>
          <div class="paper-buttons">
            
              <!-- <a class="button" href="" target="_blank">Paper</a> -->
              <a class="button" href="https://arxiv.org/abs/2403.02781" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/PromptKD" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://zhengli97.github.io/PromptKD/" target="_blank">Project Page</a>
            

            
              <a class="button" href="https://zhengli97.github.io/PromptKD/chinese_interpertation.html" target="_blank">中文解读</a>
            

            
              <a class="button" href="https://www.techbeat.net/talk-info?id=915" target="_blank">视频解读</a>
            

            
            <a class="button" href="https://github.com/zhengli97/PromptKD/blob/main/docs/PromptKD_chinese_version.pdf" target="_blank">中文版</a>
            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Dual Teachers for Self-Knowledge Distillation.</b></p>
          <p><b>Zheng Li</b>, Xiang Li, Lingfeng Yang, Renjie Song, Jian Yang<sup>#</sup>, Zhigeng Pan.</p>
          <p><b>PR 2024</b></p>
          <p>DTSKD explores a new self-KD framework where the student network receives self-supervisions by <i>dual teachers</i> from two dramatically distinct fields.</p>
          <div class="paper-buttons">
            
              <!-- <a class="button" href="" target="_blank">Paper</a> -->
              <a class="button" href="https://www.sciencedirect.com/science/article/pii/S0031320324001730" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/DTSKD" target="_blank">Code</a>
            

            

            

            
              <a class="button" href="https://zhuanlan.zhihu.com/p/690877571" target="_blank">中文解读</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Curriculum Temperature for Knowledge Distillation.</b></p>
          <p><b>Zheng Li</b>, Xiang Li<sup>#</sup>, Lingfeng Yang, Borui Zhao, Renjie Song, Lei Luo, Jun Li, Jian Yang<sup>#</sup>.</p>
          <p><b>AAAI 2023</b></p>
          <p>CTKD organizes the distillation task from easy to hard through a <i>dynamic and learnable temperature</i>.</p>
          <div class="paper-buttons">
            
              <!-- <a class="button" href="" target="_blank">Paper</a> -->
              <a class="button" href="https://arxiv.org/abs/2211.16231" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/CTKD" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://zhengli97.github.io/CTKD" target="_blank">Project Page</a>
            

            
              <a class="button" href="https://zhengli97.github.io/CTKD/chinese_interpertation.html" target="_blank">中文解读</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Online Knowledge Distillation for Efficient Pose Estimation.</b></p>
          <p><b>Zheng Li</b>, Jingwen Ye, Mingli Song, Ying Huang, Zhigeng Pan<sup>#</sup>.</p>
          <p><b>ICCV 2021</b></p>
          <p>OKDHP first proposes to distill the pose structure knowledge in a <i>one-stage</i> manner.</p>
          <div class="paper-buttons">
            
              <!-- <a class="button" href="" target="_blank">Paper</a> -->
              <a class="button" href="https://arxiv.org/abs/2108.02092" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/OKDHP" target="_blank">Code</a>
            

            

            

            
              <a class="button" href="https://zhengli97.github.io/OKDHP/chinese_interpertation.html" target="_blank">中文解读</a>
            

            

            

          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Online Knowledge Distillation via Multi-branch Diversity Enhancement.</b></p>
          <p><b>Zheng Li</b>, Ying Huang, Defang Chen, Tianren Luo, Ning Cai, Zhigeng Pan<sup>#</sup>.</p>
          <p><b>ACCV 2020</b></p>
          <p>OKDMDE is a simple and effective technique to enhance <i>model diversity</i> in online knowledge distillation.</p>
          <div class="paper-buttons">
            
              <!-- <a class="button" href="" target="_blank">Paper</a> -->
              <a class="button" href="https://arxiv.org/abs/2010.00795" target="_blank">Paper</a>
            

            

            

            

            

            

            

            

            

            

          </div>
        </div>
      
    </div>

    <!-- for all papers -->
    <div class="tab-pane" id="papers-all">
      
        <div class="paper">
          <p class="title"><b>Advancing Textual Prompt Learning with Anchored Attributes.</b></p>
          <p><b>Zheng Li</b>, Yibing Song, Ming-Ming Cheng, Xiang Li<sup>#</sup>, Jian Yang<sup>#</sup>.</p>
          <p><i>arxiv 2024</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2412.09442" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/ATPrompt" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://zhengli97.github.io/ATPrompt/" target="_blank">Project Page</a>
            

            
              <a class="button" href="https://zhuanlan.zhihu.com/p/11787739769" target="_blank">中文解读</a>
            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Cascade Prompt Learning for Vision-Language Model Adaptation.</b></p>
          <p>Ge Wu, Xin Zhang, <b>Zheng Li</b>, Zhaowei Chen, Jiajun Liang, Jian Yang, Xiang Li<sup>#</sup>.</p>
          <p><i>ECCV 2024</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2409.17805" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/megvii-research/CasPL" target="_blank">Code</a>
            

            

            

            
              <a class="button" href="https://zhuanlan.zhihu.com/p/867291664" target="_blank">中文解读</a>
            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>PromptKD: Unsupervised Prompt Distillation for Vision-Language Models.</b></p>
          <p><b>Zheng Li</b>, Xiang Li<sup>#</sup>, Xinyi Fu, Xin Zhang, Weiqiang Wang, Shuo Chen, Jian Yang<sup>#</sup></p>
          <p><i>CVPR 2024</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2403.02781" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/PromptKD" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://zhengli97.github.io/PromptKD/" target="_blank">Project Page</a>
            

            
              <a class="button" href="https://zhengli97.github.io/PromptKD/chinese_interpertation.html" target="_blank">中文解读</a>
            
             
            
              <a class="button" href="https://www.techbeat.net/talk-info?id=915" target="_blank">视频解读</a>
            

            
              <a class="button" href="https://github.com/zhengli97/PromptKD/blob/main/docs/PromptKD_chinese_version.pdf" target="_blank">中文版</a>
            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Dual Teachers for Self-Knowledge Distillation.</b></p>
          <p><b>Zheng Li</b>, Xiang Li, Lingfeng Yang, Renjie Song, Jian Yang<sup>#</sup>, Zhigeng Pan.</p>
          <p><i>PR 2024</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://www.sciencedirect.com/science/article/pii/S0031320324001730" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/DTSKD" target="_blank">Code</a>
            

            

            

            
              <a class="button" href="https://zhuanlan.zhihu.com/p/690877571" target="_blank">中文解读</a>
            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>GEIKD: Self-knowledge Distillation based on Gated Ensemble Networks and Influences-based Label Noise Removal.</b></p>
          <p>Fuchang Liu, Yu Wang, <b>Zheng Li</b>, Zhigeng Pan<sup>#</sup>.</p>
          <p><i>CVIU 2023</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://www.sciencedirect.com/science/article/pii/S1077314223001510" target="_blank">Paper</a>
            

            

            

            

            

            

            

            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?</b></p>
          <p><b>Zheng Li</b>, Yuxuan Li, Penghai Zhao, Renjie Song, Xiang Li<sup>#</sup>, Jian Yang<sup>#</sup>.</p>
          <p><i>Arxiv Preprint 2023</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2305.12954" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/DM-KD" target="_blank">Code</a>
            

            

            

            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Curriculum Temperature for Knowledge Distillation.</b></p>
          <p><b>Zheng Li</b>, Xiang Li<sup>#</sup>, Lingfeng Yang, Borui Zhao, Renjie Song, Lei Luo, Jun Li, Jian Yang<sup>#</sup>.</p>
          <p><i>AAAI 2023</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2211.16231" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/CTKD" target="_blank">Code</a>
            

            

            
              <a class="button" href="https://zhengli97.github.io/CTKD" target="_blank">Project Page</a>
            

            
              <a class="button" href="https://zhengli97.github.io/CTKD/chinese_interpertation.html" target="_blank">中文解读</a>
            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Online Knowledge Distillation for Efficient Pose Estimation.</b></p>
          <p><b>Zheng Li</b>, Jingwen Ye, Mingli Song, Ying Huang, Zhigeng Pan<sup>#</sup>.</p>
          <p><i>ICCV 2021</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2108.02092" target="_blank">Paper</a>
            

            

            

            

            
              <a class="button" href="https://github.com/zhengli97/OKDHP" target="_blank">Code</a>
            

            

            

            
              <a class="button" href="https://zhengli97.github.io/OKDHP/chinese_interpertation.html" target="_blank">中文解读</a>
            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Online Knowledge Distillation via Multi-branch Diversity Enhancement.</b></p>
          <p><b>Zheng Li</b>, Ying Huang, Defang Chen, Tianren Luo, Ning Cai, Zhigeng Pan<sup>#</sup>.</p>
          <p><i>ACCV 2020</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://arxiv.org/abs/2010.00795" target="_blank">Paper</a>
            

            

            

            

            

            

            

            
             
            

            
             
          </div>
        </div>
      
        <div class="paper">
          <p class="title"><b>Dream-experiment: a MR user interface with natural multi-channel interaction for virtual experiments.</b></p>
          <p>Tianren Luo, Mingmin Zhang<sup>#</sup>, Zhigeng Pan<sup>#</sup>, <b>Zheng Li</b>, Ning Cai, Jinda Miao, Youbin Chen, Mingxi Xu.</p>
          <p><i>TVCG 2020</i></p>
           <div class="paper-buttons">
            
              <a class="button" href="https://ieeexplore.ieee.org/abstract/document/9199566" target="_blank">Paper</a>
            

            

            

            
              <a class="button" href="https://www.youtube.com/watch?v=HfIQz4min1E" target="_blank">Video</a>
            

            

            

            

            
             
            

            
             
          </div>
        </div>
      
    </div>
  </div>
</div>

<div class="docs-section" id="experience">
  <h4>Experiences</h4>
  <h5>Education</h5>
  <ul>
    <li>Sep.2022 - Present. Ph.D., Computer Science and Technology, Nankai University. </li>
    <li>Sep.2019 - June.2022. M.Eng., Computer Applied Technology, Hangzhou Normal University.</li>
    <li>Sep.2015 - June.2019. B.Eng., Telecommunication Engineering, North China University of Science and Technology.</li>
  </ul>

  <h5>Internship</h5>
  <ul>
    <li>June.2024 - June. 2025. <a href="https://damo.alibaba.com/">DAMO Academy</a>, Alibaba Group, Hangzhou. Research Intern. Mentored by <a href="https://scholar.google.com/citations?user=oRhJHmIAAAAJ">Dr. Yibing Song</a>.</li>
    <li>Sep.2023 - June.2024. Security and Risk Management Department, <a href="https://www.antgroup.com/">Ant Group,</a> Hangzhou. Research Intern. Mentored by <a href="https://scholar.google.com/citations?user=t1gqx_cAAAAJ">Xinyi Fu</a> and <a href="https://scholar.google.com/citations?user=rbaNwV8AAAAJ">Dr. Xing Fu</a>.</li>
    <li>Oct.2021 - Aug.2023. <a href="https://megvii.com/">Megvii Research</a>, Nanjing. Research Intern. Mentored by <a href="https://scholar.google.com/citations?user=-EgH8oIAAAAJ">Renjie Song</a>.</li>
  </ul>

  <h5>Competition</h5>
  <h6>Kaggle Competition Master. <a href="https://www.kaggle.com/mdlszhengli">[Profile]</a></h6>
  <ul>
    <li>Nov.2019. "Understanding Clouds from Satellite Images." Rank: 7th/1538 (Top 1%). Gold Medal. <a href="https://www.kaggle.com/c/understanding_cloud_organization">[Link]</a> <a href="https://www.kaggle.com/c/understanding_cloud_organization/discussion/117974">[Solution]</a></li>
    <li>Apr.2018. "2018 Data Science Bowl." Rank: 8th/3634 (Top 1%). Solo Gold Medal. <a href="https://www.kaggle.com/c/data-science-bowl-2018">[Link]</a> <a href="https://www.kaggle.com/c/data-science-bowl-2018/discussion/54838#316229">[Solution]</a></li>
  </ul>
</div>


<div class="docs-section" id="misc">
  <h4>Misc</h4>
  <h5>Personal Hobbies</h5>
  <ul>
    <li>Photography 📸: I am a contracted photographer for <a href="https://500px.com.cn/">500px Gallery</a>. Here are some <a href=https://500px.com.cn/zhengliphoto"">photos</a> I took while traveling and mountaineering. </li>
    <li>Mountaineering 🗻: Summit: <a href="https://en.wikipedia.org/wiki/Haba_Snow_Mountain">Haba Snow Mountain</a> (5396m).</li>
    <li>Trail Running 🏃‍♂️ <a href="https://itra.run/RunnerSpace/li.zheng/5425908">[iTRA]</a>: 
      <ul>
        <li><a href="https://itra.run/Races/RaceDetails/97291">TNF100 Ultra Trail Challenge Moganshan - 30km Group.</a> Finish: 5h 28min (32km/1680m+).</li>
        <li><a href="https://itra.run/Races/RaceDetails/102061">Ultra-Trail Xiamen by UTMB - 20KM Group.</a> Finish: 4h 24min (28KM/990m+).</li>
      </ul>
    </li>
  </ul>
</div>

<!-- ========== PROJECTS ========== 
<div class="docs-section" id="projects">
  <h4>Projects</h4>

  <ul class="tab-nav">
    <li><div class="button active" data-ref="#projects-selected">Selected</div></li>
    <li><div class="button" data-ref="#projects-all">All</div></li>
  </ul>

  <div class="tab-content">
    <div class="tab-pane active" id="projects-selected">
      
      
    </div>

    <div class="tab-pane" id="projects-all">
      
    </div>
  </div>

</div>
-->

<!-- ========== RESUME ========== -->
<!-- <div class="docs-section" id="resume">
  <h4>Vitæ</h4>

  <p>Full Resume in <a href=/assets/cv/cv_web.pdf target="_blank">PDF</a>.</p> -->

  <!-- The Timeline -->
  <!-- <ul class="timeline">
    
  </ul>
</div> -->

<!-- <div class="docs-section" id="template">
  <h4>Website Design</h4>
  Since I made this website, many people have found this Jekyll template useful [
  
  ].
  <br/>-->
  <!-- You can find all the code needed to build your website in this <a href="https://github.com/msaveski/www_personal" target="_blank">GitHub repo</a>.
  Feel free to use it. <br/>

  If you end up using it, please link to here and drop me an email.
  I'm always happy to see people using it.
</div>   -->


    <div class="footer">
      <div class="row">
        <div class="four columns">
          Zheng Li (李政)
        </div>
        <div class="four columns">
          Last Update: 2025/04
        </div>
        <div class="four columns">
          <!-- <span onclick="window.open('')" style="cursor: pointer">
            <i class="fa-brands fa-bluesky fa-sm" style="padding-top: 10px"></i>
          </span>

          <span onclick="window.open('')" style="cursor: pointer">
            <i class="fa-brands fa-twitter"></i>
          </span>

          <span onclick="window.open('')" style="cursor: pointer">
            <i class="fa-brands fa-linkedin"></i> -->
          <!-- </span> -->

          <!-- <span onclick="window.open('https://github.com/zhengli97')" style="cursor: pointer">
            <i class="fa-brands fa-github"></i>
          </span>

          <span onclick="window.open('https://scholar.google.com/citations?user=qhKtNSIAAAAJ&hl=en')" style="cursor: pointer">
            <i class="ai ai-google-scholar" aria-hidden="true"></i>
          </span> -->
          <div class="ten columns">
            Per Aspera Ad Astra.
          </div>
        </div>
      </div>
    </div>

  </div>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');

</script>

  <!-- do not remove -->
  <span id="62cd7b7da1aff3196fdc26b60e396df9"></span>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
